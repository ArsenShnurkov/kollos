% Copyright 2012 Jeffrey Kegler
% This document is not part of the Marpa or Marpa::R2 source.
% Although it may be included with a Marpa distribution that
% is under an open source license, this document is
% not under that open source license.
% Jeffrey Kegler retains full rights.
\documentclass{amsart}
\usepackage{algorithm}
\usepackage{algpseudocode}

\newcommand{\comment}[1]{}
\newcommand{\myspace}{\mbox{ }\ \ \ \ }
\newcommand{\myspacem}{\;\;\;\;\;}
\newcommand{\sep}{\,\mid\,}
\newcommand{\mydot}{\raisebox{.15em}{\tiny $\,\bullet\,$}}
\newcommand{\size}[1]{\left | {#1} \right |} 
\newcommand{\order}[1]{{\cal O}(#1)}

\newcommand{\cfg}{CFG}
\newcommand{\nonterm}{\mbox{$V_{{\rm N}}$}}
\newcommand{\myterm}{\mbox{$V_{{\rm T}}$}}

\newcommand{\de}{\rightarrow}
\newcommand{\derivg}[1]{\mathrel{\mbox{$\:\Rightarrow\:$}}}
\newcommand{\derivrg}[2]{\mathrel{\mbox{$\:\stackrel{\!{#1}}%
        {\Rightarrow\!}\:$}}}

\newcommand{\ep}{\varepsilon}

\mathchardef\mhyphen="2D
\newcommand{\of}{\mhyphen of}

\newcommand{\ah}[1]{#1_{AH}}
\newcommand{\eim}[1]{#1_{EIM}}
\newcommand{\es}[1]{#1_{ES}}
\newcommand{\sym}[1]{#1_{SYM}}
\newcommand{\term}[1]{#1_{TERM}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\DeclareMathOperator{\scanned}{scanned}
\DeclareMathOperator{\Hyp}{Hyp}
\DeclareMathOperator{\myL}{L}
% We want to use this outside of pseudocode, as well
\newcommand\call[2]{\textproc{#1}\ifthenelse{\equal{#2}{}}{}{(#2)}}%

\hyphenation{ALGOL}

\begin{document}

\title{The Marpa Recognizer}

\author{Jeffrey Kegler}

\begin{abstract}
This paper reports describes the recognizer portion
of the Marpa algorithm.
The Marpa algorithm is a practical, and fully implemented,
algorithm for the recognition,
parsing and evaluation of context-free grammars.
Marpa's recognizer is based
an Earley's algorithm,
and merges the improvements to Earley's
from Leo~\cite{Leo::1991}
and Aycock and Horspool~\cite{AH2002}.
Their combination in the marpa parse engine
has an added feature:
It makes available,
before each token is scanned,
full knowledge of the state of the parse so far.
This allows input to be altered as the parse progresses,
which can be an extremely powerful technique.
\end{abstract}

\maketitle

\section{Introduction}

Despite the promise of general context-free parsing,
and the strong academic literature behind it,
it has never been incorporated into a tool
as widely available as yacc or
regular expressions.
The Marpa project was begun to end this neglect by
pulling the best results from the literature,
and to turn them into a widely-available tool.
A stable version of this tool, Marpa::XS, was
delivered to the CPAN Perl archive on Solstice Day
in 2011.

Marpa::XS is a complete implementation of a parser
generator.
Its recognizer is built around a parse engine,
which is new, but which also owes a great debt
to previous work.

\section{Preliminaries}
\label{s:prel}

I assume familiarity with standard grammar notation
(pages 14-15 in Aho and Ullman~\cite{AU1972}).
In the past,
The type system required to support
a theory of parsing has been taken
as a challenge to the typographic
imagination,
and often resulted in one to the eyesight.
This paper will often
supplement the standard notation,
using subscripts to indicate the commonly occuring types.
In general, variable will contain a capital
letter, constants will be all lower case.
For example, $\sym{a}$ and $\sym{b}$ would be symbol constants,
while $\sym{X}$ will be a variable whose value is a symbol.

Where $ABC$ is a set of symbols,
let $ABC^\ast$ be the set of all strings formed
from those symbols.
Let $ABC^+$ be the subset of $ABC^\ast$ that
contains all of its elements that are not of zero length.

For the purposes of this paper consider,
without loss of generality,
a grammar $g$,
and a set of symbols, $alphabet$.
Call the language of $g$, $\myL(g)$,
where $\myL(g) \in alphabet^\ast$
Let its input be $w$, $w \in alphabet$.
Divide $alphabet$ into two disjoint sets,
$term$ and $nonterm$.

For the rewriting, designate a set of duples, $rules$,
where $\forall Rule \sep Rule \in rules$,
$Rule$ takes the form $\sym{l} \de r$,
where $\sym{l} \in nonterm$ and 
$r \in (nonterm \cup term)^+$. 
$sym{l}$ is referred to as the left hand side (LHS)
of $Rule$.
$r$ is referred to as the right hand side (RHS)
of $Rule$.
This definition differs from the traditional one in
that the empty RHS is not allowed.
Let one symbol $\sym{start}$, $\sym{start} \in nonterm$,
be a dedicated start symbol.

The grammar $g$ can be defined as the 4-tuple
$(term, nonterm, rules, \sym{start})$.
Without loss of generality,
it is assumed that $g$ is "augmented",
so that there is a rule $\sym{start} \de \sym{old\mhyphen start}$,
and that $\sym{start}$ is not the LHS of any other rule,
or in the RHS of any rule.

I was already noted
that no rules of $g$ is allowed to be empty -- to
have a zero-length RHS.
Further, no symbol may be a proper nullable --
all symbol must be either nulling or non-nullable.
These restrictions follow Aycock and Horspool~\cite{AH2002}.

Aycock and Horspool did allow a single empty start rule
to deal with null parses.
Marpa eliminates all need for empty rules in its grammar
by dealing with null parses as a special case.
Marpa also deals with
trivial grammars (those which recognize only the null string)
as a special case.

The elimination of empty rules and proper nullables
is done by rewriting the grammar.
This can be done without loss of generality
and, In their paper~\cite{AH2002},
Aycock and Horspool
show how to do this
without effect on the time complexity
as a function of the input size.
Very importantly,
this rewrite is done in such a way that the semantics
of the original grammar can be efficiently reconstructed
at evaluation time.

In this paper, $Earley$ will refer to the Earley's original
recognizer~\cite{Earley:1970}.
$Leo$ will refer to Leo's revision of $Earley$
as described in his 1991 paper~\cite{Leo:1991}.
$AH$ will refer to the Aycock and Horsool's revision
of $Earley$
as described in their 2002 paper~\cite{AH:2002}.
Where $Recce$ is a recognizer,
$\call{Recce}{g}$ will be the language accepted by $Recce$.

\section{AHFA States}
\label{s:AHFA}

In this paper a
"split LR(0) $\epsilon$-DFA"
a described by Aycock and Horspool~\cite{AH2002},
will be called an Aycock-Horspool Finite Automaton,
or AHFA.
Let FA be the AHFA derived from $G$.
as described in~\cite{AH2002}.

A full description of how to derive an AHFA in theory
can be found in \cite{AH2002},
and examples of how to derive it in practice
can be found in the code for various release of Marpa.
Here I will just summarize the central ideas behind AHFA's.

Aycock and Horspool based their AHFA's
on a few observations.
First, in practice, Earley items with the same dotted rule
often appear in groups in the Earley sets,
where the entire shares the same origin.
Second, there was already in the literature a method
for associating groups of dotted rules that often appear together
when parsing.
This method was the LR(0) DFA used in the much-studied
LALR and LR parsers.
Third, the LR(0) items that are the components of LR(0)
states are, exactly, dotted rules.
Fourth, by taking into account symbols which derive the
null string, the LR(0) DFA could be turned into an
LR(0) $\epsilon$-DFA, which would be even more effective
at grouping dotted rules which occur together.

AHFA states are sets of dotted rules.
Aycock and Horspool realized that by changing Earley items
to track AHFA states, instead of individual dotted rules,
the size of Earley sets could be reduced,
and Earley's algorithm made faster in practice.
In short, then, AHFA states are a shorthand that Earley items
can use for groups of dotted rules that occur together frequently.
The original Earley items could be represented as $(r_{DOTTED}, origin)$
duples, where $r_{DOTTED}$ is a dotted rule.
Aycock and Horspool modified their Earley items to be $(\ah{L}, origin)$
duples, where $\ah{L}$ is an AHFA state.

\section{The Ruby Slippers Recognizer}
\label{s:recce}

\begin{algorithm}[H]
\caption{Ruby Slippers Initialization}\label{a:rs:initial}
\begin{algorithmic}[1] 
\Procedure{Initial}{$i,a$}
\State \Call{AddItems}{$0, \ah{start}, 0$}
\EndProcedure
\end{algorithmic} 
\end{algorithm}

\begin{algorithm}[H]
\caption{Ruby Slippers Scanning}\label{a:rs:scan}
\begin{algorithmic}[1] 
\Procedure{Scan}{$i,a$}
\Comment{Scan a token $a$, which starts at Earley set $i$}
\For{each Earley item $\eim{x}$ in $ES[i]$}
\State $\ah{to} \gets GOTO(\eim{x}.AHFA, a)$
\Call{AddState}{$i+1, \ah{to}, Origin\of(\eim{x}$}
\If{$\ah{to} \neq \Lambda$}
\State add Earley item $[\ah{to}, origin]$ to $ES[i+1]$
\EndIf
\EndFor
\EndProcedure
\end{algorithmic} 
\end{algorithm}

\begin{algorithm}[H]
\caption{Ruby Slippers Completion}\label{a:rs:complete}
\begin{algorithmic}[1] 
\Procedure{Complete}{$i_{LOC}$}
\For{each Earley item $\eim{work} \in ES[i]$}
\For{each completed rule, $LHS_{SYM} \de RHS_{SYM}[0], ...$}
\For{each $\eim{predecessor} \in ES[Origin\of \eim{work}]$}
\State $\ah{to} \gets GOTO(AHFA\of \eim{predecessor}, LHS_{SYM})$
\Call{AddState}{$to_{AHFA}, Origin\of \eim{predecessor}$}
\EndFor
\EndFor
\EndFor
\EndProcedure
\end{algorithmic} 
\end{algorithm}

\begin{algorithm}[H]
\caption{Ruby Slippers, Adding EIM Pairs}\label{a:rs:pair}
\begin{algorithmic}[1] 
\Procedure{Add EIMs}{$i_{LOC},\ah{discovered},origin_{LOC}$}
\State $\ah{predicted} \gets \Lambda$
\If{$\ah{to} \neq \Lambda$}
\State add Earley item $[\ah{to}, origin_{LOC}]$ to $ES[i]$
\State $\ah{predicted} \gets GOTO(\ah{to}, \epsilon)$
\EndIf
\If{$predicted_{AHFA} \neq \Lambda$}
\State add Earley item $[\ah{predicted}, i]$ to $ES[i]$
\EndIf
\EndProcedure
\end{algorithmic} 
\end{algorithm} 

\section{Ruby Slippers Correctness}
\label{s:leo:proof}

In this section I will show that a
Ruby Slippers
parse engine without Leo items
produces the same Earley items
as AH2002,
so that
correctness follows
from the correctness proofs
in AH2002\cite{AH2002}.
In the following,
$\es{AH[i]}$ is Earley set $i$ according
to AH2002;
$\es{RS[i]}$ is Earley set $i$ according
to the Ruby Slippers algorithm;
and $\scanned(\es{x})$ is the subset
of $\es{x}$,
that consists of all, and of only,
the its scanned Earley items.
Let the induction hypothesis, $Hyp(n)$ be
$\forall i, 0<i<n, \es{AH[i]} = \es{RS[i]}$.

\begin{lemma}\label{t:rs:correctness:basis}
$Hyp(0)$
\end{lemma}
\begin{proof}
Note that Earley set 0 never contains scanned items.
By inspection of \ref{a:rs:initial},
and comparision with AH2002, we have
$\es{AH[0]} = \es{RS[0]}$.
\end{proof}

\begin{lemma}\label{t:rs:correctness:step1}
\begin{multline*}
\Hyp(i) \wedge \call{Scan}{i,\term{input[i]}} \Longrightarrow \\
\Hyp(i) \wedge \scanned(\es{AH[i+1]}) = \scanned(\es{RS[i+1]})
\end{multline*}
\end{lemma}
\begin{proof}
From inspection of \ref{a:rs:scan}
and comparision with AH2002.
\end{proof}

\begin{lemma}\label{t:rs:correctness:step2}
\begin{multline*}
\Hyp(i) \wedge \scanned(\es{AH[i+1]}) = \scanned(\es{RS[i+1]})
\wedge \call{Complete}{i+1} \Longrightarrow \\
\Hyp(i+1)
\end{multline*}
\end{lemma}
\begin{proof}
From inspection of \ref{a:rs:complete}
and comparision with AH2002.
\end{proof}

\begin{theorem}
\begin{equation*}
\forall n, 0<n<\size(input) \rightarrow \Hyp(n)
\end{equation*}
\end{theorem}
\begin{proof}
By induction, with \ref{t:rs:correctness:basis}
as the basis and 
\ref{t:rs:correctness:step1}
and 
\ref{t:rs:correctness:step2}
as the steps.
\end{proof}

\section{Ruby Slippers time complexity}
\label{s:rs:complexity}

\section{Marpa recognizer correctness}
\label{s:rs:correctness}

\begin{theorem}
\begin{equation*}
\call{Marpa}{g} = \myL{g}
\end{equation*}
\end{theorem}

\section{Marpa recognizer time complexity}
\label{s:rs:complexity}

\section{Concluding remarks}
\label{s:disc}

\bibliographystyle{plain}

\begin{thebibliography}{10}

\bibitem{AU1972}
Alfred H.~Aho and Jeffrey D.~Ullman
\newblock The Theory of Parsing, Translation, and Computing
\newblock Prentice-Hall, Englewood Cliff, N.J., 1972.

\bibitem{AH2002}
John~Aycock and R.~Nigel~Horspool
\newblock Practical Earley Parsing
\newblock \em{The Computer Journal},
    Vol. 45, No. 6, 2002, pp. 620-630.

\bibitem{Earley:70}
J.~Earley.
\newblock An efficient context-free parsing algorithm.
\newblock {\em Communications of the Association for Computing Machinery},
  13(2):94--102, 1970.

\bibitem{GJ2008}
Dirk~Grune and Ceriel~J.H Jacobs
\newblock {\em Parsing Techniques: A Practical Guide}.
\newblock Springer, Amsterdam, 2008.

\bibitem{JK2011}
Jeffrey~Kegler, 2011: Marpa-XS-1.002000.
\newblock [Available online at http://search.cpan.org/dist/Marpa-XS/.]

\bibitem{Leo::1991}
J.~M. I.~M. Leo.
\newblock A general context-free parsing algorithm running in linear time on
  every {LR($k$)} grammar without using lookahead.
\newblock {\em Theoretical Computer Science}, 82:165--176, 1991.

\end{thebibliography}
 
\end{document}
