\documentclass{amsart}
\usepackage{algorithm}
\usepackage{algpseudocode}

\newcommand{\comment}[1]{}
\newcommand{\myspace}{\mbox{ }\ \ \ \ }
\newcommand{\myspacem}{\;\;\;\;\;}
\newcommand{\sep}{\,\mid\,}
\newcommand{\mydot}{\raisebox{.15em}{\tiny $\,\bullet\,$}}
\newcommand{\size}[1]{\left | {#1} \right |} 
\newcommand{\rank}[1]{\mbox{$r({#1})$}} 
\newcommand{\order}[1]{\cal O(#1)}

\newcommand{\cfg}{CFG}

\newcommand{\nonterm}{\mbox{$V_{{\rm N}}$}}
\newcommand{\myterm}{\mbox{$V_{{\rm T}}$}}

\newcommand{\de}{\rightarrow}
\newcommand{\derivg}[1]{\mathrel{\mbox{$\:\Rightarrow\:$}}}
\newcommand{\derivrg}[2]{\mathrel{\mbox{$\:\stackrel{\!{#1}}%
        {\Rightarrow\!}\:$}}}

\newcommand{\rlc}{\mathrel{\angle}}
\newcommand{\rlcp}{\mathrel{\angle^+}}
\newcommand{\rlcm}{\mathrel{\angle^\ast}}
\newcommand{\ep}{\varepsilon}

\newcommand{\goto}{\mbox{{\it goto\/}}}
\newcommand{\prd}{\mbox{{\it prd\/}}}
\newcommand{\gto}{\mbox{$goto_1$}}
\newcommand{\gtt}{\mbox{$goto_2$}}

\newcommand{\eset}{I_{{\rm E}}}
\newcommand{\ieset}{I_{{\rm V}}}
\newcommand{\chartset}{I_{{\rm C}}}
\newcommand{\pred}{\mbox{{\it pred\/}}}

\mathchardef\mhyphen="2D
\newcommand{\of}{\mhyphen of}
\newcommand{\eim}[1]{#1_{EIM}}
\newcommand{\term}[1]{#1_{TERM}}
\newcommand{\es}[1]{#1_{ES}}
\newcommand{\ah}[1]{#1_{AH}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\DeclareMathOperator{\scanned}{scanned}
\DeclareMathOperator{\Hyp}{Hyp}
% We want to use this outside of pseudocode, as well
\newcommand\call[2]{\textproc{#1}\ifthenelse{\equal{#2}{}}{}{(#2)}}%

\hyphenation{ALGOL}

\begin{document}

\title{The Marpa Recognizer}

\author{Jeffrey Kegler}

\begin{abstract}
This paper reports describes the recognizer portion
of the Marpa algorithm.
The Marpa algorithm is a practical, and fully implemented,
algorithm for the recognition,
parsing and evaluation of context-free grammars.
Marpa's recognizer is based
an Earley's algorithm,
and merges the improvements to Earley's
from Leo~\cite{LEO91}
and Aycock and Horspool~\cite{AH2002}.
Their combination in the marpa parse engine
has an added feature:
It makes available,
before each token is scanned,
full knowledge of the state of the parse so far.
This allows input to be altered as the parse progresses,
which can be an extremely powerful technique.
\end{abstract}

\maketitle

\section{Introduction}

Despite the promise of general context-free parsing,
and the strong academic literature behind it,
it has never been incorporated into a tool
as widely available as yacc or
regular expressions.
The Marpa project was begun to end this neglect by
pulling the best results from the literature,
and to turn them into a widely-available tool.
A stable version of this tool, Marpa::XS, was
delivered to the CPAN Perl archive on Solstice Day
in 2011.

Marpa::XS is a complete implementation of a parser
generator.
Its recognizer is built around a parse engine,
which is new, but which also owes a great debt
to previous work.

\section{Preliminaries}
\label{s:prel}

I assume familiarity with standard grammar notation
(pages 14-15 in~\cite{GJ2008}).
Let grammar 
$G$ be $(\myterm, \nonterm, P, S)$,
has been augmented with a dedicated start rule
$Start_{RULE} = [ Start_{SYM} \de S' ]$
and that the dedicated start symbol
$Start_{SYM}$ such that
$Start_{SYM} \in \nonterm, Start_{SYM} \neq S'$
appears only in $Start_{RULE}$.

In this paper a
"split LR(0) $\epsilon$-DFA"
a described by Aycock and Horspool~\cite{AH2002},
will be called an Aycock-Horspool Finite Automaton,
or AHFA.
Let FA be the AHFA derived from $G$.
as described in~\cite{AH2002}.

\section{AHFA States}
\label{s:AHFA}

A full description of how to derive an AHFA in theory
can be found in \cite{AH2002},
and examples of how to derive it in practice
can be found in the code for various release of Marpa.
Here I will just summarize the central ideas behind AHFA's.

Aycock and Horspool based their AHFA's
on a few observations.
First, in practice, Earley items with the same dotted rule
often appear in groups in the Earley sets,
where the entire shares the same origin.
Second, there was already in the literature a method
for associating groups of dotted rules that often appear together
when parsing.
This method was the LR(0) DFA used in the much-studied
LALR and LR parsers.
Third, the LR(0) items that are the components of LR(0)
states are, exactly, dotted rules.
Fourth, by taking into account symbols which derive the
null string, the LR(0) DFA could be turned into an
LR(0) $\epsilon$-DFA, which would be even more effective
at grouping dotted rules which occur together.

AHFA states are sets of dotted rules.
Aycock and Horspool realized that by changing Earley items
to track AHFA states, instead of individual dotted rules,
the size of Earley sets could be reduced,
and Earley's algorithm made faster in practice.
In short, then, AHFA states are a shorthand that Earley items
can use for groups of dotted rules that occur together frequently.
The original Earley items could be represented as $(r_{DOTTED}, origin)$
duples, where $r_{DOTTED}$ is a dotted rule.
Aycock and Horspool modified their Earley items to be $(\ah{L}, origin)$
duples, where $\ah{L}$ is an AHFA state.

\section{The Ruby Slippers Recognizer}
\label{s:recce}

\begin{algorithm}
\caption{Ruby Slippers Initialization}\label{a:rs:initial}
\begin{algorithmic}[1] 
\Procedure{Initial}{$i,a$}
\State \Call{AddItems}{$0, \ah{start}, 0$}
\EndProcedure
\end{algorithmic} 
\end{algorithm}

\begin{algorithm}
\caption{Ruby Slippers Scanning}\label{a:rs:scan}
\begin{algorithmic}[1] 
\Procedure{Scan}{$i,a$}
\Comment{Scan a token $a$, which starts at Earley set $i$}
\For{each Earley item $\eim{x}$ in $ES[i]$}
\State $\ah{to} \gets GOTO(\eim{x}.AHFA, a)$
\Call{AddState}{$i+1, \ah{to}, Origin\of(\eim{x}$}
\If{$\ah{to} \neq \Lambda$}
\State add Earley item $[\ah{to}, origin]$ to $ES[i+1]$
\EndIf
\EndFor
\EndProcedure
\end{algorithmic} 
\end{algorithm}

\begin{algorithm}
\caption{Ruby Slippers Completion}\label{a:rs:complete}
\begin{algorithmic}[1] 
\Procedure{Complete}{$i_{LOC}$}
\For{each Earley item $\eim{work} \in ES[i]$}
\For{each completed rule, $LHS_{SYM} \de RHS_{SYM}[0], ...$}
\For{each $\eim{predecessor} \in ES[Origin\of \eim{work}]$}
\State $\ah{to} \gets GOTO(AHFA\of \eim{predecessor}, LHS_{SYM})$
\Call{AddState}{$to_{AHFA}, Origin\of \eim{predecessor}$}
\EndFor
\EndFor
\EndFor
\EndProcedure
\end{algorithmic} 
\end{algorithm}

\begin{algorithm}
\caption{Ruby Slippers, Adding EIM Pairs}\label{a:rs:pair}
\begin{algorithmic}[1] 
\Procedure{Add EIMs}{$i_{LOC},\ah{discovered},origin_{LOC}$}
\State $\ah{predicted} \gets \Lambda$
\If{$\ah{to} \neq \Lambda$}
\State add Earley item $[\ah{to}, origin_{LOC}]$ to $ES[i]$
\State $\ah{predicted} \gets GOTO(\ah{to}, \epsilon)$
\EndIf
\If{$predicted_{AHFA} \neq \Lambda$}
\State add Earley item $[\ah{predicted}, i]$ to $ES[i]$
\EndIf
\EndProcedure
\end{algorithmic} 
\end{algorithm} 

\section{Correctness without Leo items}
\label{s:leo:proof}

In this section I will show that a
Ruby Slippers
parse engine without Leo items
produces the same Earley items
as AH2002,
so that
correctness follows
from the correctness proofs
in AH2002\cite{AH2002}.
In the following,
$\es{AH[i]}$ is Earley set $i$ according
to AH2002;
$\es{RS[i]}$ is Earley set $i$ according
to the Ruby Slippers algorithm;
and $\scanned(\es{x})$ is the subset
of $\es{x}$,
that consists of all, and of only,
the its scanned Earley items.
Let the induction hypothesis, $Hyp(n)$ be
$\forall i, 0<i<n, \es{AH[i]} = \es{RS[i]}$.

\begin{lemma}\label{t:rs:correct:basis}
$Hyp(0)$
\end{lemma}
\begin{proof}
Note that Earley set 0 never contains scanned items.
By inspection of \ref{a:rs:initial},
and comparision with AH2002, we have
$\es{AH[0]} = \es{RS[0]}$.
\end{proof}

\begin{lemma}\label{t:rs:correct:step0}
\begin{multline*}
\Hyp(i) \wedge \call{Scan}{i,\term{input[i]}} \Longrightarrow \\
\Hyp(i) \wedge \scanned(\es{AH[i+1]}) = \scanned(\es{RS[i+1]})
\end{multline*}
\end{lemma}
\begin{proof}
From inspection of \ref{a:rs:scan}
and comparision with AH2002.
\end{proof}

\begin{lemma}\label{t:rs:correct:step1}
\begin{multline*}
\Hyp(i) \wedge \scanned(\es{AH[i+1]}) = \scanned(\es{RS[i+1]})
\wedge \call{Complete}{i+1} \Longrightarrow \\
\Hyp(i+1)
\end{multline*}
\end{lemma}
\begin{proof}
From inspection of \ref{a:rs:complete}
and comparision with AH2002.
\end{proof}

\begin{theorem}
\begin{equation*}
\forall n, 0<n<\size(input) \rightarrow \Hyp(n)
\end{equation*}
\end{theorem}
\begin{proof}
By induction, with \ref{t:rs:correct:basis}
as the basis and 
\ref{t:rs:correct:step1}
and 
\ref{t:rs:correct:step2}
as the steps.
\end{proof}

\section{Concluding Remarks}
\label{s:disc}

\bibliographystyle{plain}

\begin{thebibliography}{10}

\bibitem{AH2002}
John~Aycock and R.~Nigel~Horspool
\newblock Practical Earley Parsing
\newblock \em{The Computer Journal},
    Vol. 45, No. 6, 2002, pp. 620-630.

\bibitem{Earley:70}
J.~Earley.
\newblock An efficient context-free parsing algorithm.
\newblock {\em Communications of the Association for Computing Machinery},
  13(2):94--102, 1970.

\bibitem{GJ2008}
Dirk~Grune and Ceriel~J.H Jacobs
\newblock {\em Parsing Techniques: A Practical Guide}.
\newblock Springer, Amsterdam, 2008.

\bibitem{LEO91}
J.~M. I.~M. Leo.
\newblock A general context-free parsing algorithm running in linear time on
  every {LR($k$)} grammar without using lookahead.
\newblock {\em Theoretical Computer Science}, 82:165--176, 1991.

\end{thebibliography}
 
\end{document}
