json_kir =
{
  -- tokens in l0 are at a lower level than
  -- "tokens" as defined in RFC 7159, section 2
  -- RFC 7159 does not separate semantics from syntax --
  -- if you assume either top-down parsing (as in recursive
  -- descent) or a dedicated lexer (as in yacc) there's no
  -- need to make the separation.
  l0 = {
    irules = {
      -- ws before and after <value>, see RFC 7159, section 2
      { lhs=ws_before, rhs={ ws }, lexeme=true },
      { lhs=ws_after, rhs={ ws }, lexeme=true },
      -- next rules are ws ::= ws_char*
      { lhs=ws, rhs={ ws_seq } },
      { lhs=ws_seq, rhs={ ws_seq ws_char } },
      { lhs=ws_seq, rhs={ ws_char } },
      { lhs=ws_seq, rhs={ } }, -- empty
      { lhs=begin_array rhs = { ws lsquare ws }, lexeme=true },
      { lhs=begin_object, rhs = { ws lsquare ws }, lexeme=true},
      { lhs=end_array, rhs = { ws rsquare ws }, lexeme=true},
      { lhs=end_object, rhs = { ws rcurly ws }, lexeme=true},
      { lhs=name_separator, rhs = { ws colon ws }, lexeme=true},
      { lhs=value_separator, rhs = { ws comma ws }, lexeme=true},
      { lhs=false, rhs = { char_f, char_a, char_l, char_s, char_e }, lexeme=true},
      { lhs=true, rhs = { char_t, char_r, char_u, char_e }, lexeme=true},
      { lhs=null, rhs = { char_n, char_u, char_l, char_l }, lexeme=true},
      { lhs=minus, rhs = { char_minus }, lexeme=true},

      -- Lua number format seems to be compatible with JSON,
      -- so we treat a JSON number as a full token
      { lhs=number, rhs = { opt_minus, int, opt_frac, opt_exp }, lexeme=true},
      { lhs=decimal_point, rhs = { dot }},
      { lhs=opt_minus, rhs = { char_minus } },
      { lhs=opt_minus, rhs = { } },
      { lhs=opt_exp, rhs = { exp } },
      { lhs=opt_exp, rhs = { } },
      { lhs=exp, rhs = { e_or_E, opt_sign , digit_seq } },
      { lhs=opt_sign, rhs = { } },
      { lhs=opt_sign, rhs = { char_minus } },
      { lhs=opt_sign, rhs = { char_plus } },
      { lhs=opt_frac, rhs = { } },
      { lhs=opt_frac, rhs = { frac } },
      { lhs=frac, rhs = { dot, digit_seq } },
      { lhs=int, rhs = { char_nonzero, digit_seq } },
      { lhs=digit_seq, rhs = { digit_seq, char_digit } },
      { lhs=digit_seq, rhs = { char_digit } },

      -- we divide up the standards string token, because we
      -- need to do semantic processing on its pieces
      { lhs=quote, rhs = { escape_char, quote_char }, lexeme=true },
      { lhs=backslash, rhs = { escape_char, backslash_char }, lexeme=true },
      { lhs=slash, rhs = { escape_char, slash_char }, lexeme=true },
      { lhs=backspace, rhs = { escape_char, letter_b }, lexeme=true },
      { lhs=formfeed, rhs = { escape_char, letter_f }, lexeme=true },
      { lhs=linefeed, rhs = { escape_char, letter_n }, lexeme=true },
      { lhs=carriage_return, rhs = { escape_char, letter_r }, lexeme=true },
      { lhs=tab, rhs = { escape_char, letter_t }, lexeme=true },
      { lhs=hex_char, rhs = { escape_char, letter_u, hex_digit, hex_digit, hex_digit, hex_digit }, lexeme=true },
      { lhs=simple_string, rhs = { escape_char, unescaped_char_seq }, lexeme=true },
      { lhs=unescaped_char_seq, rhs = { unescaped_char_seq, unescaped_char } },
      { lhs=unescaped_char_seq, rhs = { unescaped_char } },

    },

    charclasses = {
      slash_char = "[\047]",
      backslash_char = "[\092]",
      escape_char = "[\092]",
      unescaped_char = "[ !\035-\091\093-\255]",
      ws_char = "[\009\010\013\032]",
      lsquare = "[\091]",
      lcurly = "[{]",
      hexdigit = "[%x]",
      rsquare = "[\093]",
      rcurly = "[}]",
      colon = "[:]",
      comma = "[,]",
      dot = "[.]",
      quote = '["]',
      char_zero = "[0]",
      char_nonzero = "[1-9]",
      char_digit = "[0-9]",
      char_minus = '[-]',
      char_minus = '[+]',
      char_a = "[a]",
      char_b = "[b]",
      char_E = "[E]",
      char_e = "[e]",
      char_i = "[i]",
      char_f = "[f]",
      char_l = "[l]",
      char_n = "[n]",
      char_r = "[r]",
      char_s = "[s]",
      char_t = "[t]",
      char_u = "[u]",
    }
  }
}

